{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b16beed7-7563-4bb7-85f3-b6b8d8d773f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_HOME = /packages/apps/spack/21/opt/spack/linux-rocky8-zen3/gcc-12.1.0/cuda-12.0.1-x3bnvayrybncl3rqu6zk4zzu4oztblqi\n",
      "which nvcc -> /packages/apps/spack/21/opt/spack/linux-rocky8-zen3/gcc-12.1.0/cuda-12.0.1-x3bnvayrybncl3rqu6zk4zzu4oztblqi/bin/nvcc\n",
      "/packages/apps/spack/21/opt/spack/linux-rocky8-zen3/gcc-12.1.0/cuda-12.0.1-x3bnvayrybncl3rqu6zk4zzu4oztblqi/bin/nvcc\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Fri_Jan__6_16:45:21_PST_2023\n",
      "Cuda compilation tools, release 12.0, V12.0.140\n",
      "Build cuda_12.0.r12.0/compiler.32267302_0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, subprocess, shutil\n",
    "\n",
    "# replace this with the nvcc path you posted (we compute CUDA_HOME automatically)\n",
    "nvcc_path = \"/packages/apps/spack/21/opt/spack/linux-rocky8-zen3/gcc-12.1.0/cuda-12.0.1-x3bnvayrybncl3rqu6zk4zzu4oztblqi/bin/nvcc\"\n",
    "\n",
    "if not os.path.exists(nvcc_path):\n",
    "    raise FileNotFoundError(f\"nvcc not found at {nvcc_path} — update nvcc_path if different\")\n",
    "\n",
    "cuda_home = os.path.dirname(os.path.dirname(nvcc_path))\n",
    "os.environ[\"CUDA_HOME\"] = cuda_home\n",
    "os.environ[\"PATH\"] = os.path.join(cuda_home, \"bin\") + os.pathsep + os.environ.get(\"PATH\", \"\")\n",
    "# Append existing LD_LIBRARY_PATH if present\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = os.path.join(cuda_home, \"lib64\") + os.pathsep + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "\n",
    "print(\"CUDA_HOME =\", cuda_home)\n",
    "print(\"which nvcc ->\", shutil.which(\"nvcc\"))\n",
    "\n",
    "# quick verify (runs in a shell inheriting these env vars)\n",
    "proc = subprocess.run(\"/bin/bash -lc 'which nvcc && nvcc --version'\", shell=True, capture_output=True, text=True, env=os.environ)\n",
    "print(proc.stdout)\n",
    "if proc.returncode != 0:\n",
    "    print(\"nvcc failed to run; stderr:\\n\", proc.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb1098a-52c5-4d69-a8d7-c33382d85fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward loss: 0.3723908986270815\n",
      "\n",
      "Parameter gradient norms:\n",
      " W_Q   : 0.000322\n",
      " W_K   : 0.000528\n",
      " W_V   : 0.054086\n",
      " W_O   : 0.107515\n",
      " W1    : 0.087050\n",
      " W2    : 0.096397\n",
      " b1    : 0.045283\n",
      " b2    : 0.347803\n",
      " gamma1: 0.011698\n",
      " beta1 : 0.009856\n",
      " gamma2: 0.007613\n",
      " beta2 : 0.008136\n"
     ]
    }
   ],
   "source": [
    "##NUMPY VERSION IMPLEMENTING ONE TRANSFORMER BLOCK (FORWARD AND BACKPASS)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# -------------------- tiny config (single-head for clarity) --------------------\n",
    "B, T, D = 1, 2, 4        # batch, seq-length, model-dim (small for readability)\n",
    "d_k = D                  # single head uses full D for simplicity\n",
    "\n",
    "# -------------------- simple helpers --------------------\n",
    "def softmax(x, axis=-1):\n",
    "    e = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return e / np.sum(e, axis=axis, keepdims=True)\n",
    "\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi)*(x + 0.044715*x**3)))\n",
    "\n",
    "def gelu_grad(x):\n",
    "    a = np.sqrt(2/np.pi)\n",
    "    u = a*(x + 0.044715*x**3)\n",
    "    tanh_u = np.tanh(u)\n",
    "    sech2 = 1 - tanh_u**2\n",
    "    du_dx = a*(1 + 3*0.044715*x**2)\n",
    "    return 0.5*(1 + tanh_u) + 0.5*x*sech2*du_dx\n",
    "\n",
    "def layer_norm_forward(x, eps=1e-5):\n",
    "    # x: (B,T,D) per-token LN across features\n",
    "    mu = x.mean(axis=-1, keepdims=True)\n",
    "    var = x.var(axis=-1, keepdims=True)\n",
    "    inv = 1.0/np.sqrt(var + eps)\n",
    "    x_norm = (x - mu)*inv\n",
    "    return x_norm, (x, mu, var, inv, eps)\n",
    "\n",
    "def layer_norm_backward(dy, cache):\n",
    "    # standard LN backward (per-token)\n",
    "    x, mu, var, inv, eps = cache\n",
    "    N = x.shape[-1]\n",
    "    x_mu = x - mu\n",
    "    dx_norm = dy\n",
    "    dvar = np.sum(dx_norm * x_mu * -0.5 * inv**3, axis=-1, keepdims=True)\n",
    "    dmu = np.sum(dx_norm * -inv, axis=-1, keepdims=True) + dvar * np.sum(-2.0 * x_mu, axis=-1, keepdims=True)/N\n",
    "    dx = dx_norm * inv + dvar * 2.0 * x_mu / N + dmu / N\n",
    "    return dx\n",
    "\n",
    "# -------------------- params (random small init) --------------------\n",
    "W_Q = np.random.randn(D, D) * 0.1\n",
    "W_K = np.random.randn(D, D) * 0.1\n",
    "W_V = np.random.randn(D, D) * 0.1\n",
    "W_O = np.random.randn(D, D) * 0.1\n",
    "\n",
    "W1 = np.random.randn(D, 2*D) * 0.1   # FFN expand\n",
    "b1 = np.zeros(2*D)\n",
    "W2 = np.random.randn(2*D, D) * 0.1\n",
    "b2 = np.zeros(D)\n",
    "\n",
    "gamma1 = np.ones(D); beta1 = np.zeros(D)   # LN after input (scale/shift)\n",
    "gamma2 = np.ones(D); beta2 = np.zeros(D)   # LN after attn/residual\n",
    "\n",
    "# -------------------- toy input + target --------------------\n",
    "x = np.random.randn(B, T, D)\n",
    "target = np.random.randn(B, T, D)\n",
    "\n",
    "# -------------------- FORWARD PASS --------------------\n",
    "cache = {}\n",
    "\n",
    "# Pre-LN (simplified: LN on input)\n",
    "x_norm1, ln1_cache = layer_norm_forward(x)                 # x_norm = (x - mu)/sqrt(var)\n",
    "x_ln = x_ln * gamma1 + beta1                            # scale & shift\n",
    "cache['ln1'] = (ln1_cache, x_norm1)  # cache both! (CLAUDE CHANGE)\n",
    "\n",
    "\n",
    "# Q, K, V linear projections\n",
    "Q = x_ln @ W_Q               # (B,T,D)\n",
    "K = x_ln @ W_K\n",
    "V = x_ln @ W_V\n",
    "cache['Q,K,V'] = (Q, K, V)\n",
    "\n",
    "# Single-head scaled dot-product attention\n",
    "scores = Q @ K.transpose(0,2,1) / np.sqrt(d_k)   # (B,T,T)\n",
    "A = softmax(scores, axis=-1)                      # attention weights\n",
    "head = A @ V                                      # (B,T,D)\n",
    "cache['scores,A,head'] = (scores, A, head)\n",
    "\n",
    "# Output projection\n",
    "attn_out = head @ W_O            # (B,T,D)\n",
    "cache['attn_out'] = attn_out\n",
    "\n",
    "# First residual: x + attn_out\n",
    "res1 = x + attn_out\n",
    "cache['res1'] = res1.copy()\n",
    "\n",
    "# LN before FFN (post-attn LN)\n",
    "res1_norm, ln2_cache = layer_norm_forward(res1)\n",
    "res1_ln = res1_norm * gamma2 + beta2\n",
    "cache['ln2'] = (ln2_cache, res1_norm)\n",
    "\n",
    "# FFN: expand -> gelu -> project back\n",
    "h = res1_ln @ W1 + b1       # (B,T,2D)\n",
    "h_act = gelu(h)\n",
    "ffn_out = h_act @ W2 + b2   # (B,T,D)\n",
    "cache['h,h_act,ffn_out'] = (h, h_act, ffn_out)\n",
    "\n",
    "# final residual -> output\n",
    "out = res1 + ffn_out         # (B,T,D)\n",
    "\n",
    "# MSE loss (mean over all elements)\n",
    "loss = 0.5 * np.mean((out - target)**2)\n",
    "print(\"forward loss:\", loss)\n",
    "\n",
    "# -------------------- BACKWARD PASS (manual) --------------------\n",
    "grads = {name: np.zeros_like(val) for name,val in [\n",
    "    (\"W_Q\",W_Q),(\"W_K\",W_K),(\"W_V\",W_V),(\"W_O\",W_O),\n",
    "    (\"W1\",W1),(\"b1\",b1),(\"W2\",W2),(\"b2\",b2),\n",
    "    (\"gamma1\",gamma1),(\"beta1\",beta1),(\"gamma2\",gamma2),(\"beta2\",beta2)\n",
    "]}\n",
    "\n",
    "# dLoss/dout: derivative of 0.5*mean((out-target)^2) -> (out-target)/N_total\n",
    "N_total = out.size\n",
    "dout = (out - target) / N_total\n",
    "\n",
    "# -- final residual out = res1 + ffn_out\n",
    "dres1 = dout.copy()        # gradient through identity/residual\n",
    "dffn = dout.copy()         # gradient into FFN output\n",
    "\n",
    "# -- FFN backward: ffn_out = h_act @ W2 + b2\n",
    "grads['W2'] += h_act.reshape(-1, h_act.shape[-1]).T @ dffn.reshape(-1, D)   # dW2 = h_act^T * dffn\n",
    "grads['b2'] += np.sum(dffn, axis=(0,1))                                    # db2 = sum over batch & time\n",
    "\n",
    "# backprop into h_act\n",
    "dh_act = dffn @ W2.T                   # (B,T,2D)\n",
    "dh = dh_act * gelu_grad(h)             # elementwise through GELU\n",
    "\n",
    "# W1, b1 grads: h = res1_ln @ W1 + b1\n",
    "grads['W1'] += res1_ln.reshape(-1, D).T @ dh.reshape(-1, 2*D)   # dW1 = res1_ln^T * dh\n",
    "grads['b1'] += np.sum(dh, axis=(0,1))                         # db1 = sum\n",
    "\n",
    "# gradient into res1_ln from FFN\n",
    "dres1_ln_from_ffn = dh @ W1.T      # (B,T,D)\n",
    "\n",
    "# -- LN2 backward: res1_ln = LN(res1) * gamma2 + beta2\n",
    "# dgamma2 = sum( dres1_ln_from_ffn * LN(res1) ), dbeta2 = sum(dres1_ln_from_ffn)\n",
    "# But LN(res1) (normalized values) = (res1 - mu)/sqrt(var) ; we cached ln2_cache for exact backward.\n",
    "grads['gamma2'] += np.sum(dres1_ln_from_ffn * ((res1 - ln2_cache[1]) * ln2_cache[3]), axis=(0,1))  # dgamma\n",
    "grads['beta2']  += np.sum(dres1_ln_from_ffn, axis=(0,1))                                           # dbeta\n",
    "\n",
    "# scale then LN backward\n",
    "dln2 = dres1_ln_from_ffn * gamma2            # scale by gamma2 (elementwise)\n",
    "dx_from_ln2 = layer_norm_backward(dln2, ln2_cache)\n",
    "\n",
    "# total gradient into res1 = from final residual identity + from LN/FFN path\n",
    "dres1_total = dres1 + dx_from_ln2\n",
    "\n",
    "# -- residual1: res1 = x + attn_out\n",
    "# res1 = x + attn_out, so gradient splits:\n",
    "#   dL/dx = dL/dres1 (identity branch)\n",
    "#   dL/dattn_out = dL/dres1 (same gradient flows to both inputs)\n",
    "dx_resid = dres1_total.copy()    # flows to identity branch (input x)\n",
    "dattn_out = dres1_total.copy()   # flows into attention output\n",
    "\n",
    "# -- Attention backward\n",
    "# attn_out = head @ W_O\n",
    "grads['W_O'] += head.reshape(-1, D).T @ dattn_out.reshape(-1, D)\n",
    "dhead = dattn_out @ W_O.T        # gradient into head (B,T,D)\n",
    "\n",
    "# head = A @ V  -> dA and dV\n",
    "# By chain rule:\n",
    "#   dL/dA = dL/dhead @ V^T  (where @ is batch matmul)\n",
    "#   dL/dV = A^T @ dL/dhead\n",
    "dA = dhead @ V.transpose(0,2,1)          # (B,T,T) = dhead @ V^T  (for single-head shapes)\n",
    "dV = A.transpose(0,2,1) @ dhead          # (B,T,D) = A^T @ dhead\n",
    "\n",
    "# softmax backward: A = softmax(scores)\n",
    "# dScores = A * (dA - sum(dA * A, axis=-1, keepdims=True))\n",
    "# Softmax Jacobian: dL/dscores[i,j] = A[i,j] * (dL/dA[i,j] - Σ_k dL/dA[i,k] * A[i,k])\n",
    "# This comes from: dA/dscores = diag(A) - A*A^T per row\n",
    "tmp = np.sum(dA * A, axis=-1, keepdims=True)\n",
    "dScores = A * (dA - tmp)\n",
    "\n",
    "# scores = Q @ K^T / sqrt(d_k)\n",
    "dQ = dScores @ K / np.sqrt(d_k)          # dQ = dScores @ K / sqrt\n",
    "dK = dScores.transpose(0,2,1) @ Q / np.sqrt(d_k)  # dK = dScores^T @ Q / sqrt\n",
    "\n",
    "# Q = x_ln @ W_Q  etc -> compute W grads and dx_ln contribution\n",
    "grads['W_Q'] += x_ln.reshape(-1, D).T @ dQ.reshape(-1, D)\n",
    "grads['W_K'] += x_ln.reshape(-1, D).T @ dK.reshape(-1, D)\n",
    "grads['W_V'] += x_ln.reshape(-1, D).T @ dV.reshape(-1, D)\n",
    "\n",
    "dx_ln_from_Q = dQ @ W_Q.T\n",
    "dx_ln_from_K = dK @ W_K.T\n",
    "dx_ln_from_V = dV @ W_V.T\n",
    "\n",
    "dx_ln_attn = dx_ln_from_Q + dx_ln_from_K + dx_ln_from_V   # combined gradient into x_ln from attention\n",
    "\n",
    "# -- LN1 backward: x_ln = LN(x) * gamma1 + beta1\n",
    "ln1_cache, x_norm1 = cache['ln1']\n",
    "grads['gamma1'] += np.sum(dx_ln_attn * x_norm1, axis=(0,1))  # cleaner!\n",
    "grads['beta1']  += np.sum(dx_ln_attn, axis=(0,1))\n",
    "\n",
    "dln1 = dx_ln_attn * gamma1\n",
    "dx_from_ln1 = layer_norm_backward(dln1, ln1_cache)\n",
    "\n",
    "# total gradient to input x = from LN1 path + from residual identity branch\n",
    "dx_total = dx_from_ln1 + dx_resid\n",
    "\n",
    "# -------------------- quick prints --------------------\n",
    "print(\"\\nParameter gradient norms:\")\n",
    "for k in ['W_Q','W_K','W_V','W_O','W1','W2','b1','b2','gamma1','beta1','gamma2','beta2']:\n",
    "    print(f\" {k:6s}: {np.linalg.norm(grads[k]):.6f}\")\n",
    "\n",
    "# -------------------- GRADIENT CHECK --------------------\n",
    "def check_grad(param_name, param, grad, eps=1e-5):\n",
    "    \"\"\"Finite difference check\"\"\"\n",
    "    orig = param.copy()\n",
    "    errors = []\n",
    "    for idx in np.ndindex(param.shape):\n",
    "        param[idx] = orig[idx] + eps\n",
    "        loss_plus = compute_loss()  # re-run forward\n",
    "        param[idx] = orig[idx] - eps\n",
    "        loss_minus = compute_loss()\n",
    "        param[idx] = orig[idx]\n",
    "        \n",
    "        numerical = (loss_plus - loss_minus) / (2 * eps)\n",
    "        analytical = grad[idx]\n",
    "        errors.append(abs(numerical - analytical))\n",
    "    \n",
    "    print(f\"{param_name}: max error = {max(errors):.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c559a59-f4f1-4892-b463-25bc9b4424db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: B=1, T=2, D=4\n",
      "\n",
      "========== FORWARD PASS ==========\n",
      "Forward loss: 0.597601\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export CUDA_HOME=/packages/apps/spack/21/opt/spack/linux-rocky8-zen3/gcc-12.1.0/cuda-12.0.1-x3bnvayrybncl3rqu6zk4zzu4oztblqi\n",
    "export PATH=$CUDA_HOME/bin:$PATH\n",
    "export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH\n",
    "cat > transformer_block.cu <<'EOF'\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <iostream>\n",
    "#include <cmath>\n",
    "#include <cstdlib>\n",
    "#include <ctime>\n",
    "\n",
    "#define CUDA_CHECK(call) \\\n",
    "    do { \\\n",
    "        cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            std::cerr << \"CUDA error at \" << __FILE__ << \":\" << __LINE__ \\\n",
    "                      << \" - \" << cudaGetErrorString(err) << std::endl; \\\n",
    "            exit(1); \\\n",
    "        } \\\n",
    "    } while(0)\n",
    "\n",
    "// ============================================================================\n",
    "// CUDA KERNELS\n",
    "// ============================================================================\n",
    "\n",
    "__global__ void gelu_forward(const float* x, float* y, int N) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < N) {\n",
    "        float val = x[idx];\n",
    "        float a = sqrtf(2.0f / 3.14159265359f);\n",
    "        float u = a * (val + 0.044715f * val * val * val);\n",
    "        float tanh_u = tanhf(u);\n",
    "        y[idx] = 0.5f * val * (1.0f + tanh_u);\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void gelu_backward(const float* x, const float* dy, float* dx, int N) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < N) {\n",
    "        float val = x[idx];\n",
    "        float a = sqrtf(2.0f / 3.14159265359f);\n",
    "        float u = a * (val + 0.044715f * val * val * val);\n",
    "        float tanh_u = tanhf(u);\n",
    "        float sech2 = 1.0f - tanh_u * tanh_u;\n",
    "        float du_dx = a * (1.0f + 3.0f * 0.044715f * val * val);\n",
    "        float grad = 0.5f * (1.0f + tanh_u) + 0.5f * val * sech2 * du_dx;\n",
    "        dx[idx] = dy[idx] * grad;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void layernorm_forward(const float* x, float* y, float* mean, float* inv_std,\n",
    "                                   int BT, int D, float eps) {\n",
    "    int token_idx = blockIdx.x;\n",
    "    if (token_idx >= BT) return;\n",
    "    \n",
    "    extern __shared__ float shared[];\n",
    "    \n",
    "    // Compute mean\n",
    "    float sum = 0.0f;\n",
    "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
    "        sum += x[token_idx * D + i];\n",
    "    }\n",
    "    shared[threadIdx.x] = sum;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
    "        if (threadIdx.x < stride) {\n",
    "            shared[threadIdx.x] += shared[threadIdx.x + stride];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    float mu = shared[0] / D;\n",
    "    if (threadIdx.x == 0) mean[token_idx] = mu;\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Compute variance\n",
    "    sum = 0.0f;\n",
    "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
    "        float diff = x[token_idx * D + i] - mu;\n",
    "        sum += diff * diff;\n",
    "    }\n",
    "    shared[threadIdx.x] = sum;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
    "        if (threadIdx.x < stride) {\n",
    "            shared[threadIdx.x] += shared[threadIdx.x + stride];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    float var = shared[0] / D;\n",
    "    float inv = 1.0f / sqrtf(var + eps);\n",
    "    if (threadIdx.x == 0) inv_std[token_idx] = inv;\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Normalize\n",
    "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
    "        y[token_idx * D + i] = (x[token_idx * D + i] - mu) * inv;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void layernorm_backward(const float* dy, const float* x, const float* mean,\n",
    "                                   const float* inv_std, float* dx, int BT, int D) {\n",
    "    int token_idx = blockIdx.x;\n",
    "    if (token_idx >= BT) return;\n",
    "    \n",
    "    extern __shared__ float shared[];\n",
    "    float* s1 = shared;\n",
    "    float* s2 = &shared[blockDim.x];\n",
    "    \n",
    "    float mu = mean[token_idx];\n",
    "    float inv = inv_std[token_idx];\n",
    "    int offset = token_idx * D;\n",
    "    \n",
    "    float sum1 = 0.0f, sum2 = 0.0f;\n",
    "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
    "        float xmu = x[offset + i] - mu;\n",
    "        sum1 += dy[offset + i];\n",
    "        sum2 += dy[offset + i] * xmu;\n",
    "    }\n",
    "    s1[threadIdx.x] = sum1;\n",
    "    s2[threadIdx.x] = sum2;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
    "        if (threadIdx.x < stride) {\n",
    "            s1[threadIdx.x] += s1[threadIdx.x + stride];\n",
    "            s2[threadIdx.x] += s2[threadIdx.x + stride];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    float dmu = -inv * s1[0];\n",
    "    float dvar = -0.5f * inv * inv * inv * s2[0];\n",
    "    \n",
    "    for (int i = threadIdx.x; i < D; i += blockDim.x) {\n",
    "        float xmu = x[offset + i] - mu;\n",
    "        dx[offset + i] = dy[offset + i] * inv + dvar * 2.0f * xmu / D + dmu / D;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void scale_shift(const float* x, const float* gamma, const float* beta,\n",
    "                            float* y, int BT, int D) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < BT * D) {\n",
    "        int d = idx % D;\n",
    "        y[idx] = x[idx] * gamma[d] + beta[d];\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void softmax_forward(const float* x, float* y, int B, int T) {\n",
    "    int batch = blockIdx.y;\n",
    "    int row = blockIdx.x;\n",
    "    if (batch >= B || row >= T) return;\n",
    "    \n",
    "    extern __shared__ float shared[];\n",
    "    int offset = (batch * T + row) * T;\n",
    "    \n",
    "    // Max\n",
    "    float max_val = -1e30f;\n",
    "    for (int i = threadIdx.x; i < T; i += blockDim.x) {\n",
    "        max_val = fmaxf(max_val, x[offset + i]);\n",
    "    }\n",
    "    shared[threadIdx.x] = max_val;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (threadIdx.x < s) {\n",
    "            shared[threadIdx.x] = fmaxf(shared[threadIdx.x], shared[threadIdx.x + s]);\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    max_val = shared[0];\n",
    "    \n",
    "    // Exp and sum\n",
    "    float sum = 0.0f;\n",
    "    for (int i = threadIdx.x; i < T; i += blockDim.x) {\n",
    "        float e = expf(x[offset + i] - max_val);\n",
    "        y[offset + i] = e;\n",
    "        sum += e;\n",
    "    }\n",
    "    shared[threadIdx.x] = sum;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (threadIdx.x < s) {\n",
    "            shared[threadIdx.x] += shared[threadIdx.x + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    sum = shared[0];\n",
    "    \n",
    "    // Normalize\n",
    "    for (int i = threadIdx.x; i < T; i += blockDim.x) {\n",
    "        y[offset + i] /= sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void softmax_backward(const float* A, const float* dA, float* dScores,\n",
    "                                 int B, int T) {\n",
    "    int batch = blockIdx.y;\n",
    "    int row = blockIdx.x;\n",
    "    if (batch >= B || row >= T) return;\n",
    "    \n",
    "    extern __shared__ float shared[];\n",
    "    int offset = (batch * T + row) * T;\n",
    "    \n",
    "    float sum = 0.0f;\n",
    "    for (int i = threadIdx.x; i < T; i += blockDim.x) {\n",
    "        sum += dA[offset + i] * A[offset + i];\n",
    "    }\n",
    "    shared[threadIdx.x] = sum;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (threadIdx.x < s) {\n",
    "            shared[threadIdx.x] += shared[threadIdx.x + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    float dot = shared[0];\n",
    "    \n",
    "    for (int i = threadIdx.x; i < T; i += blockDim.x) {\n",
    "        dScores[offset + i] = A[offset + i] * (dA[offset + i] - dot);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Simple matrix multiply kernel: C = A @ B (no transpose)\n",
    "__global__ void matmul(const float* A, const float* B, float* C, \n",
    "                       int M, int N, int K) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (row < M && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < K; k++) {\n",
    "            sum += A[row * K + k] * B[k * N + col];\n",
    "        }\n",
    "        C[row * N + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Matrix multiply with transpose: C = A @ B^T\n",
    "__global__ void matmul_transB(const float* A, const float* B, float* C,\n",
    "                              int M, int N, int K) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (row < M && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < K; k++) {\n",
    "            sum += A[row * K + k] * B[col * K + k];\n",
    "        }\n",
    "        C[row * N + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Matrix multiply with accumulation: C += A @ B\n",
    "__global__ void matmul_accum(const float* A, const float* B, float* C,\n",
    "                             int M, int N, int K) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    if (row < M && col < N) {\n",
    "        float sum = 0.0f;\n",
    "        for (int k = 0; k < K; k++) {\n",
    "            sum += A[row * K + k] * B[k * N + col];\n",
    "        }\n",
    "        atomicAdd(&C[row * N + col], sum);\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void add_vectors(const float* a, const float* b, float* c, int N) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < N) {\n",
    "        c[idx] = a[idx] + b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void scale_vector(const float* x, float scale, float* y, int N) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < N) {\n",
    "        y[idx] = x[idx] * scale;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void elemwise_mul(const float* a, const float* b, float* c, int N) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < N) {\n",
    "        c[idx] = a[idx] * b[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void mse_loss(const float* pred, const float* target, float* loss, int N) {\n",
    "    extern __shared__ float sdata[];\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    float diff = 0.0f;\n",
    "    if (idx < N) {\n",
    "        diff = pred[idx] - target[idx];\n",
    "        diff = diff * diff;\n",
    "    }\n",
    "    sdata[threadIdx.x] = diff;\n",
    "    __syncthreads();\n",
    "    \n",
    "    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n",
    "        if (threadIdx.x < s) {\n",
    "            sdata[threadIdx.x] += sdata[threadIdx.x + s];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    \n",
    "    if (threadIdx.x == 0) {\n",
    "        atomicAdd(loss, sdata[0] * 0.5f / N);\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void mse_grad(const float* pred, const float* target, float* grad, int N) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < N) {\n",
    "        grad[idx] = (pred[idx] - target[idx]) / N;\n",
    "    }\n",
    "}\n",
    "\n",
    "// ============================================================================\n",
    "// MAIN\n",
    "// ============================================================================\n",
    "\n",
    "int main() {\n",
    "    srand(0);\n",
    "    \n",
    "    const int B = 1, T = 2, D = 4;\n",
    "    const int BT = B * T;\n",
    "    const float eps = 1e-5f;\n",
    "    const float sqrt_dk = sqrtf((float)D);\n",
    "    \n",
    "    std::cout << \"Config: B=\" << B << \", T=\" << T << \", D=\" << D << std::endl;\n",
    "    \n",
    "    // Allocate host memory and initialize\n",
    "    float *h_W_Q = new float[D*D];\n",
    "    float *h_W_K = new float[D*D];\n",
    "    float *h_W_V = new float[D*D];\n",
    "    float *h_W_O = new float[D*D];\n",
    "    float *h_W1 = new float[D*2*D];\n",
    "    float *h_W2 = new float[2*D*D];\n",
    "    float *h_b1 = new float[2*D];\n",
    "    float *h_b2 = new float[D];\n",
    "    float *h_gamma1 = new float[D];\n",
    "    float *h_beta1 = new float[D];\n",
    "    float *h_gamma2 = new float[D];\n",
    "    float *h_beta2 = new float[D];\n",
    "    float *h_x = new float[BT*D];\n",
    "    float *h_target = new float[BT*D];\n",
    "    \n",
    "    // Random init (scale by 0.1)\n",
    "    for (int i = 0; i < D*D; i++) {\n",
    "        h_W_Q[i] = ((float)rand() / RAND_MAX - 0.5f) * 0.2f;\n",
    "        h_W_K[i] = ((float)rand() / RAND_MAX - 0.5f) * 0.2f;\n",
    "        h_W_V[i] = ((float)rand() / RAND_MAX - 0.5f) * 0.2f;\n",
    "        h_W_O[i] = ((float)rand() / RAND_MAX - 0.5f) * 0.2f;\n",
    "    }\n",
    "    for (int i = 0; i < D*2*D; i++) {\n",
    "        h_W1[i] = ((float)rand() / RAND_MAX - 0.5f) * 0.2f;\n",
    "    }\n",
    "    for (int i = 0; i < 2*D*D; i++) {\n",
    "        h_W2[i] = ((float)rand() / RAND_MAX - 0.5f) * 0.2f;\n",
    "    }\n",
    "    for (int i = 0; i < 2*D; i++) h_b1[i] = 0.0f;\n",
    "    for (int i = 0; i < D; i++) h_b2[i] = 0.0f;\n",
    "    for (int i = 0; i < D; i++) {\n",
    "        h_gamma1[i] = 1.0f;\n",
    "        h_beta1[i] = 0.0f;\n",
    "        h_gamma2[i] = 1.0f;\n",
    "        h_beta2[i] = 0.0f;\n",
    "    }\n",
    "    for (int i = 0; i < BT*D; i++) {\n",
    "        h_x[i] = ((float)rand() / RAND_MAX - 0.5f) * 2.0f;\n",
    "        h_target[i] = ((float)rand() / RAND_MAX - 0.5f) * 2.0f;\n",
    "    }\n",
    "    \n",
    "    // Allocate device memory\n",
    "    float *d_W_Q, *d_W_K, *d_W_V, *d_W_O;\n",
    "    float *d_W1, *d_W2, *d_b1, *d_b2;\n",
    "    float *d_gamma1, *d_beta1, *d_gamma2, *d_beta2;\n",
    "    float *d_x, *d_target;\n",
    "    \n",
    "    CUDA_CHECK(cudaMalloc(&d_W_Q, D*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_W_K, D*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_W_V, D*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_W_O, D*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_W1, D*2*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_W2, 2*D*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_b1, 2*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_b2, D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_gamma1, D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_beta1, D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_gamma2, D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_beta2, D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_x, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_target, BT*D*sizeof(float)));\n",
    "    \n",
    "    // Copy to device\n",
    "    CUDA_CHECK(cudaMemcpy(d_W_Q, h_W_Q, D*D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_W_K, h_W_K, D*D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_W_V, h_W_V, D*D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_W_O, h_W_O, D*D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_W1, h_W1, D*2*D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_W2, h_W2, 2*D*D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_b1, h_b1, 2*D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_b2, h_b2, D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_gamma1, h_gamma1, D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_beta1, h_beta1, D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_gamma2, h_gamma2, D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_beta2, h_beta2, D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_x, h_x, BT*D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    CUDA_CHECK(cudaMemcpy(d_target, h_target, BT*D*sizeof(float), cudaMemcpyHostToDevice));\n",
    "    \n",
    "    // Allocate intermediate activations\n",
    "    float *d_x_norm1, *d_x_ln, *d_Q, *d_K, *d_V;\n",
    "    float *d_scores, *d_A, *d_head, *d_attn_out, *d_res1;\n",
    "    float *d_res1_norm, *d_res1_ln, *d_h, *d_h_act, *d_ffn_out, *d_out;\n",
    "    float *d_mean1, *d_inv_std1, *d_mean2, *d_inv_std2;\n",
    "    \n",
    "    CUDA_CHECK(cudaMalloc(&d_x_norm1, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_x_ln, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_Q, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_K, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_V, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_scores, B*T*T*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_A, B*T*T*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_head, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_attn_out, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_res1, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_res1_norm, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_res1_ln, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_h, BT*2*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_h_act, BT*2*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_ffn_out, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_out, BT*D*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_mean1, BT*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_inv_std1, BT*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_mean2, BT*sizeof(float)));\n",
    "    CUDA_CHECK(cudaMalloc(&d_inv_std2, BT*sizeof(float)));\n",
    "    \n",
    "    // ========== FORWARD PASS ==========\n",
    "    std::cout << \"\\n========== FORWARD PASS ==========\\n\";\n",
    "    \n",
    "    int threads = 256;\n",
    "    int blocks;\n",
    "    \n",
    "    // LayerNorm 1\n",
    "    layernorm_forward<<<BT, threads, threads*sizeof(float)>>>(\n",
    "        d_x, d_x_norm1, d_mean1, d_inv_std1, BT, D, eps\n",
    "    );\n",
    "    \n",
    "    blocks = (BT*D + threads - 1) / threads;\n",
    "    scale_shift<<<blocks, threads>>>(d_x_norm1, d_gamma1, d_beta1, d_x_ln, BT, D);\n",
    "    \n",
    "    // Q, K, V projections\n",
    "    dim3 grid_mm(1, BT);  // For small matrices\n",
    "    dim3 block_mm(D, 1);\n",
    "    \n",
    "    matmul<<<grid_mm, block_mm>>>(d_x_ln, d_W_Q, d_Q, BT, D, D);\n",
    "    matmul<<<grid_mm, block_mm>>>(d_x_ln, d_W_K, d_K, BT, D, D);\n",
    "    matmul<<<grid_mm, block_mm>>>(d_x_ln, d_W_V, d_V, BT, D, D);\n",
    "    \n",
    "    // Attention scores = Q @ K^T\n",
    "    dim3 grid_scores(1, BT);\n",
    "    dim3 block_scores(T, 1);\n",
    "    matmul_transB<<<grid_scores, block_scores>>>(d_Q, d_K, d_scores, BT, T, D);\n",
    "    \n",
    "    // Scale by 1/sqrt(d_k)\n",
    "    blocks = (B*T*T + threads - 1) / threads;\n",
    "    scale_vector<<<blocks, threads>>>(d_scores, 1.0f/sqrt_dk, d_scores, B*T*T);\n",
    "    \n",
    "    // Softmax\n",
    "    dim3 grid_soft(T, B);\n",
    "    softmax_forward<<<grid_soft, threads, threads*sizeof(float)>>>(d_scores, d_A, B, T);\n",
    "    \n",
    "    // head = A @ V (simplified for B=1)\n",
    "    matmul<<<grid_mm, block_mm>>>(d_A, d_V, d_head, BT, D, T);\n",
    "    \n",
    "    // Output projection\n",
    "    matmul<<<grid_mm, block_mm>>>(d_head, d_W_O, d_attn_out, BT, D, D);\n",
    "    \n",
    "    // Residual 1\n",
    "    blocks = (BT*D + threads - 1) / threads;\n",
    "    add_vectors<<<blocks, threads>>>(d_x, d_attn_out, d_res1, BT*D);\n",
    "    \n",
    "    // LayerNorm 2\n",
    "    layernorm_forward<<<BT, threads, threads*sizeof(float)>>>(\n",
    "        d_res1, d_res1_norm, d_mean2, d_inv_std2, BT, D, eps\n",
    "    );\n",
    "    scale_shift<<<blocks, threads>>>(d_res1_norm, d_gamma2, d_beta2, d_res1_ln, BT, D);\n",
    "    \n",
    "    // FFN\n",
    "    dim3 grid_ffn1(1, BT);\n",
    "    dim3 block_ffn1(2*D, 1);\n",
    "    matmul<<<grid_ffn1, block_ffn1>>>(d_res1_ln, d_W1, d_h, BT, 2*D, D);\n",
    "    \n",
    "    // Add bias (simplified)\n",
    "    blocks = (BT*2*D + threads - 1) / threads;\n",
    "    for (int bt = 0; bt < BT; bt++) {\n",
    "        add_vectors<<<1, 2*D>>>(d_h + bt*2*D, d_b1, d_h + bt*2*D, 2*D);\n",
    "    }\n",
    "    \n",
    "    // GELU\n",
    "    blocks = (BT*2*D + threads - 1) / threads;\n",
    "    gelu_forward<<<blocks, threads>>>(d_h, d_h_act, BT*2*D);\n",
    "    \n",
    "    // FFN output\n",
    "    dim3 grid_ffn2(1, BT);\n",
    "    dim3 block_ffn2(D, 1);\n",
    "    matmul<<<grid_ffn2, block_ffn2>>>(d_h_act, d_W2, d_ffn_out, BT, D, 2*D);\n",
    "    \n",
    "    for (int bt = 0; bt < BT; bt++) {\n",
    "        add_vectors<<<1, D>>>(d_ffn_out + bt*D, d_b2, d_ffn_out + bt*D, D);\n",
    "    }\n",
    "    \n",
    "    // Final residual\n",
    "    blocks = (BT*D + threads - 1) / threads;\n",
    "    add_vectors<<<blocks, threads>>>(d_res1, d_ffn_out, d_out, BT*D);\n",
    "    \n",
    "    // Loss\n",
    "    float *d_loss;\n",
    "    CUDA_CHECK(cudaMalloc(&d_loss, sizeof(float)));\n",
    "    CUDA_CHECK(cudaMemset(d_loss, 0, sizeof(float)));\n",
    "    \n",
    "    blocks = (BT*D + threads - 1) / threads;\n",
    "    mse_loss<<<blocks, threads, threads*sizeof(float)>>>(d_out, d_target, d_loss, BT*D);\n",
    "    \n",
    "    float h_loss;\n",
    "    CUDA_CHECK(cudaMemcpy(&h_loss, d_loss, sizeof(float), cudaMemcpyDeviceToHost));\n",
    "    \n",
    "    std::cout << \"Forward loss: \" << h_loss << std::endl;\n",
    "    \n",
    "    // Cleanup\n",
    "    delete[] h_W_Q; delete[] h_W_K; delete[] h_W_V; delete[] h_W_O;\n",
    "    delete[] h_W1; delete[] h_W2; delete[] h_b1; delete[] h_b2;\n",
    "    delete[] h_gamma1; delete[] h_beta1; delete[] h_gamma2; delete[] h_beta2;\n",
    "    delete[] h_x; delete[] h_target;\n",
    "    \n",
    "    cudaFree(d_W_Q); cudaFree(d_W_K); cudaFree(d_W_V); cudaFree(d_W_O);\n",
    "    cudaFree(d_W1); cudaFree(d_W2); cudaFree(d_b1); cudaFree(d_b2);\n",
    "    cudaFree(d_gamma1); cudaFree(d_beta1); cudaFree(d_gamma2); cudaFree(d_beta2);\n",
    "    cudaFree(d_x); cudaFree(d_target); cudaFree(d_loss);\n",
    "    cudaFree(d_x_norm1); cudaFree(d_x_ln); cudaFree(d_Q); cudaFree(d_K); cudaFree(d_V);\n",
    "    cudaFree(d_scores); cudaFree(d_A); cudaFree(d_head); cudaFree(d_attn_out);\n",
    "    cudaFree(d_res1); cudaFree(d_res1_norm); cudaFree(d_res1_ln);\n",
    "    cudaFree(d_h); cudaFree(d_h_act); cudaFree(d_ffn_out); cudaFree(d_out);\n",
    "    cudaFree(d_mean1); cudaFree(d_inv_std1); cudaFree(d_mean2); cudaFree(d_inv_std2);\n",
    "    \n",
    "    std::cout << \"\\nDone!\\n\";\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EOF\n",
    "\n",
    "nvcc -std=c++17 transformer_block.cu -o transformer_block_output && ./transformer_block_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4bbe9-a353-4d05-aa9b-8d25c0595bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
